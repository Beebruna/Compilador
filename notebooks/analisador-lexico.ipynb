{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b194108f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T13:31:55.978683Z",
     "start_time": "2022-11-22T13:31:55.934788Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "class TOKEN:\n",
    "    def __init__(self, classe, lexema, tipo):\n",
    "        self.classe = classe\n",
    "        # Transformando o parâmetro lexema obtido como lista para uma string\n",
    "        self.lexema = ''.join(lexema)\n",
    "        self.tipo = tipo\n",
    "    \n",
    "    # Define o que aparece quando se utiliza print(token)\n",
    "    def __str__(self):\n",
    "        return f'Classe={self.classe}, lexema={self.lexema}, Tipo={self.tipo}'\n",
    "\n",
    "'''\n",
    "Nova exception herdando de Exception para diferenciar quando utiliza try... except\n",
    "'''\n",
    "# \n",
    "class AlphabetError(Exception):\n",
    "    pass\n",
    "\n",
    "'''\n",
    "Tabela inicializada com palavras reservadas e ids encontrados no programa fonte\n",
    "\n",
    "'''\n",
    "TABELA_DE_SIMBOLOS = [\n",
    "    TOKEN('inicio', 'inicio', 'inicio'),\n",
    "    TOKEN('varinicio', 'varinicio', 'varinicio'),\n",
    "    TOKEN('varfim', 'varfim', 'varfim'),\n",
    "    TOKEN('escreva', 'escreva', 'escreva'),\n",
    "    TOKEN('leia', 'leia', 'leia'),\n",
    "    TOKEN('se', 'se', 'se'),\n",
    "    TOKEN('entao', 'entao', 'entao'),\n",
    "    TOKEN('fimse', 'fimse', 'fimse'),\n",
    "    TOKEN('fim', 'fim', 'fim'),\n",
    "    TOKEN('inteiro', 'inteiro', 'inteiro'),\n",
    "    TOKEN('literal', 'literal', 'literal'),\n",
    "    TOKEN('real', 'real', 'real')\n",
    "]\n",
    "\n",
    "'''\n",
    "Dicionário de dicionários representando a tabela de transição do autômato\n",
    "Para mudar de estado utiliza-se estado = tabela_de_transicao[estado atual][chave] na qual as chaves são os símbolos no\n",
    "estado atual para mudar de estado\n",
    "'''\n",
    "tabela_de_transicao = {\n",
    "    0: {\n",
    "        '(': 1,\n",
    "        ')': 2,\n",
    "        ';': 3,\n",
    "        ',': 4,\n",
    "        'EOF': 5,\n",
    "        '+': 6,\n",
    "        '-': 6,\n",
    "        '*': 6,\n",
    "        '/': 6,\n",
    "        'letra': 7,\n",
    "        '\"': 8,\n",
    "        '{': 10,\n",
    "        '<': 12,\n",
    "        '>': 14,\n",
    "        '=': 15,\n",
    "        'digito': 16\n",
    "    },\n",
    "    1: {},\n",
    "    2: {},\n",
    "    3: {},\n",
    "    4: {},\n",
    "    5: {},\n",
    "    6: {},\n",
    "    7: {\n",
    "        'letra': 7,\n",
    "        'digito': 7,\n",
    "        '_': 7\n",
    "    },\n",
    "    8: {\n",
    "        'curinga': 8,\n",
    "        '\"': 9\n",
    "    },\n",
    "    9: {},\n",
    "    10: {\n",
    "        'curinga': 10,\n",
    "        '}': 11\n",
    "    },\n",
    "    11: {},\n",
    "    12: {\n",
    "        '=': 15,\n",
    "        '>': 15,\n",
    "        '-': 13\n",
    "    },\n",
    "    13: {},\n",
    "    14: {\n",
    "        '=': 15\n",
    "    },\n",
    "    15: {},\n",
    "    16: {\n",
    "        'digito': 16,\n",
    "        '.': 17,\n",
    "        'E': 19,\n",
    "        'e': 19\n",
    "    },\n",
    "    17: {\n",
    "        'digito': 18\n",
    "    },\n",
    "    18: {\n",
    "        'digito': 18,\n",
    "        'E': 19,\n",
    "        'e': 19\n",
    "    },\n",
    "    19: {\n",
    "        'digito': 21,\n",
    "        '+': 20,\n",
    "        '-': 20\n",
    "    },\n",
    "    20: {\n",
    "        'digito': 21\n",
    "    },\n",
    "    21: {\n",
    "        'digito': 21\n",
    "    }\n",
    "}\n",
    "\n",
    "'''\n",
    "Quando o autômato termina uma cadeia em algum desses estados sabemos qual tipo de token estamos lidando\n",
    "'''\n",
    "estados_finais = {\n",
    "    0: 'estado inicial',\n",
    "    1: 'AB_P',\n",
    "    2: 'FC_P',\n",
    "    3: 'PT_V',\n",
    "    4: 'VIR',\n",
    "    5: 'EOF',\n",
    "    6: 'OPA',\n",
    "    7: 'id',\n",
    "    9: 'Lit',\n",
    "    11: 'Comentário',\n",
    "    12: 'OPR',\n",
    "    13: 'ATR',\n",
    "    14: 'OPR',\n",
    "    15: 'OPR',\n",
    "    16: 'Num',\n",
    "    18: 'Num',\n",
    "    21: 'Num'\n",
    "}\n",
    "\n",
    "'''\n",
    "Algumas listas úteis\n",
    "'''\n",
    "letras = list(string.ascii_letters)\n",
    "digitos = list(string.digits)\n",
    "delimitadores = [' ', '\\n', '\\t']\n",
    "alfabeto = list(letras + digitos + delimitadores + [\n",
    "    ',', ';', ':', '.', '!', '?', '\\\\', '*', '+', '-', '/', '(', ')', '{', '}',\n",
    "    '[', ']', '<', '>', '=', \"'\", '\"'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8f3e72e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T13:31:56.009663Z",
     "start_time": "2022-11-22T13:31:55.980665Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Essa função recebe o estado e o lexema para classificar e retornar o novo token\n",
    "'''\n",
    "def retorna_TOKEN(estado, lexema):\n",
    "    # Verifica a cadeia completa por string sem fim ou caractere fora do alfabeto\n",
    "#     for l in lexema:\n",
    "#         if ((estado == 8 or estado == 10) and l == '\\n') or (l not in alfabeto):\n",
    "#             return TOKEN('ERROR', lexema, None)\n",
    "\n",
    "    if estado == 8 or estado == 10:\n",
    "        return TOKEN('ERROR', lexema, None)\n",
    "#     for l in lexema:\n",
    "#         if ((estado == 8 or estado == 10) and l == '\\n') or (l not in alfabeto):\n",
    "#             return TOKEN('ERROR', lexema, None)\n",
    "        \n",
    "    # Se estado == 1 então é um id ou uma palavra reservada\n",
    "    if estado == 7:\n",
    "        # Se já estiver na tabela de símbolos então o token da tabela de símbolos é retornado\n",
    "        for token in TABELA_DE_SIMBOLOS:\n",
    "            # Como lexema é uma lista é necessário usar join para comparar com uma string\n",
    "            if token.lexema == ''.join(lexema):\n",
    "                return token\n",
    "        # Caso não tenha retornado então significa que foi encontrado um id que não está na tabela de símbolos\n",
    "        novo_id = TOKEN('id', lexema, None)\n",
    "        TABELA_DE_SIMBOLOS.append(novo_id)\n",
    "        return novo_id\n",
    "    \n",
    "    # Definindo o tipo do token de acordo com a descrição do trabalho\n",
    "    elif estado == 16:\n",
    "        tipo = 'inteiro'\n",
    "        \n",
    "    elif estado == 18 or estado == 21:\n",
    "        tipo = 'real'\n",
    "        \n",
    "    elif estado == 9:\n",
    "        tipo = 'literal'\n",
    "        \n",
    "    else:\n",
    "        tipo = None\n",
    "    \n",
    "    # Saída padrão caso não seja um id ou palavra reservada\n",
    "    return TOKEN(estados_finais[estado], lexema, tipo)\n",
    "\n",
    "'''\n",
    "Essa função cria a chave para a transição de estados na tabela de transições de acordo com o estado atual e o caractere\n",
    "recebido.\n",
    "\n",
    "Utiliza-se as chaves \"letra\", \"digito\" e \"curinga\" ao invés do próprio caractere para não confundir com outros caracteres\n",
    "iguais e para evitar a criação de um estado para cada letra e dígito.\n",
    "'''\n",
    "def chave(caractere, estado):\n",
    "        if (estado == 16 or estado == 18) and (caractere =='e' or caractere == 'E'):\n",
    "            chave = 'e'\n",
    "        elif (estado == 8 and caractere != '\"') or (estado == 10 and caractere != '}'):\n",
    "            chave = 'curinga'\n",
    "        elif caractere in letras:\n",
    "            chave = 'letra'\n",
    "        elif caractere in digitos:\n",
    "            chave = 'digito'\n",
    "        else:\n",
    "            chave = caractere\n",
    "            \n",
    "        return chave\n",
    "\n",
    "\n",
    "'''\n",
    "Analisador léxico.\n",
    "\n",
    "Recebe o código fonte como uma string e o lê caractere a caractere, unindo-os em lexemas que serão reconhecidos como\n",
    "pertencentes a um padrão.\n",
    "'''    \n",
    "def SCANNER(fonte, posicao, linha, coluna):\n",
    "    # Estado inicial\n",
    "    estado = 0\n",
    "    # Lexema é uma string, mas está sendo tratada como lista para facilitar operações com string\n",
    "    lexema = []\n",
    "    \n",
    "    # Lê todos os caracteres do fonte\n",
    "    while posicao <= len(fonte):\n",
    "        try:\n",
    "            # Se não pertence ao alfabeto gera uma exceção\n",
    "            if fonte[posicao] not in alfabeto:\n",
    "                raise AlphabetError\n",
    "            # Caso pertença ao alfabeto realiza a transição de estados\n",
    "            estado = tabela_de_transicao[estado][chave(fonte[posicao], estado)]\n",
    "            \n",
    "        # Foi encontrado um caractere que não pertence ao alfabeto\n",
    "        except AlphabetError:\n",
    "            # Caso exista um lexema sendo lido quando esse caractere foi encontrado retorna o token desse lexema primeiro\n",
    "            if (len(lexema) > 0) and (estado in estados_finais):\n",
    "                return retorna_TOKEN(estado, lexema), posicao, linha, coluna\n",
    "            # Caso contrário mostra onde o caractere foi encontrado e continua análise\n",
    "            print(f'ERRO LÉXICO - Caractere inválido na linguagem: {fonte[posicao]}. Linha {linha}, coluna {coluna}')\n",
    "            lexema.append(fonte[posicao])\n",
    "        \n",
    "        # Quebra de padrão: Foi feita uma tentativa de fazer uma transição inexistente naquele estado\n",
    "        except KeyError:\n",
    "            # Caso haja um lexema e está em um estado final, então é porque já chegou ao fim\n",
    "            if (len(lexema)) > 0 and (estado in estados_finais.keys()):\n",
    "                return retorna_TOKEN(estado, lexema), posicao, linha, coluna\n",
    "            # Exponenciação incompleta\n",
    "            elif estado not in estados_finais.keys() and estado == 19:\n",
    "                print(f'ERRO LÉXICO - Exponenciação incompleta. Linha {linha}, coluna {coluna}')                       \n",
    "                return TOKEN('ERROR', lexema, None), posicao, linha, coluna\n",
    "        # Chegou ao fim da string fonte\n",
    "        except IndexError:\n",
    "            # Há um lexema que deve ser retornado antes do EOF\n",
    "            if len(lexema) > 0:\n",
    "                return retorna_TOKEN(estado, lexema), posicao, linha, coluna\n",
    "            # Sai do loop e retorna o EOF\n",
    "            else: \n",
    "                break\n",
    "        \n",
    "        # Ocorreu a transição normalmente\n",
    "        else:\n",
    "            # Se o delimitador for \\n então atualiza linha e coluna\n",
    "            if fonte[posicao] == '\\n':\n",
    "                linha = linha + 1\n",
    "                coluna = 0\n",
    "                if estado == 8:\n",
    "                    print(f'ERRO LÉXICO - Literal incompleto. Linha {linha}, coluna {coluna}')\n",
    "                    return retorna_TOKEN(estado, lexema), posicao, linha, coluna\n",
    "                elif estado == 10:\n",
    "                    print(f'ERRO LÉXICO - Comentário incompleto. Linha {linha}, coluna {coluna}')\n",
    "                    return retorna_TOKEN(estado, lexema), posicao, linha, coluna\n",
    "            # Junta caractere ao lexema\n",
    "            # Não ignora delimitadores dentro de comentários e literais\n",
    "            if (fonte[posicao] not in delimitadores) or (estado == 8 or estado == 10):\n",
    "                lexema.append(fonte[posicao])\n",
    "        # Atualiza contadores\n",
    "        finally:\n",
    "            posicao = posicao + 1\n",
    "            coluna = coluna + 1\n",
    "            \n",
    "    # Fim do arquivo fonte\n",
    "    return TOKEN('EOF', 'EOF', None), posicao, linha, coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7555da85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T13:31:56.025622Z",
     "start_time": "2022-11-22T13:31:56.012656Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Função main().\n",
    "\n",
    "Lê o arquivo e faz um loop enquanto chama o SCANNER().\n",
    "'''\n",
    "def main():\n",
    "    with open('..\\\\Teste\\\\teste3.txt') as file:\n",
    "        fonte = file.read()\n",
    "        posicao = 0\n",
    "        linha = 1\n",
    "        coluna = 1\n",
    "        \n",
    "        while posicao <= len(fonte):\n",
    "            token, posicao, linha, coluna = SCANNER(fonte, posicao, linha, coluna)\n",
    "            print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5664c571",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-22T13:31:56.057610Z",
     "start_time": "2022-11-22T13:31:56.031605Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe=inicio, lexema=inicio, Tipo=inicio\n",
      "Classe=varinicio, lexema=varinicio, Tipo=varinicio\n",
      "Classe=literal, lexema=literal, Tipo=literal\n",
      "Classe=id, lexema=A, Tipo=None\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "Classe=inteiro, lexema=inteiro, Tipo=inteiro\n",
      "Classe=id, lexema=B, Tipo=None\n",
      "Classe=VIR, lexema=,, Tipo=None\n",
      "Classe=id, lexema=D, Tipo=None\n",
      "Classe=VIR, lexema=,, Tipo=None\n",
      "Classe=id, lexema=E, Tipo=None\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "Classe=real, lexema=real, Tipo=real\n",
      "Classe=id, lexema=C, Tipo=None\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "Classe=varfim, lexema=varfim, Tipo=varfim\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "Classe=escreva, lexema=escreva, Tipo=escreva\n",
      "Classe=Lit, lexema=\"Digite B:\", Tipo=literal\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "Classe=leia, lexema=leia, Tipo=leia\n",
      "Classe=id, lexema=B, Tipo=None\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "Classe=escreva, lexema=escreva, Tipo=escreva\n",
      "Classe=Lit, lexema=\"Digite A:\", Tipo=literal\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "Classe=leia, lexema=leia, Tipo=leia\n",
      "Classe=id, lexema=A, Tipo=None\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "Classe=se, lexema=se, Tipo=se\n",
      "Classe=AB_P, lexema=(, Tipo=None\n",
      "Classe=id, lexema=B, Tipo=None\n",
      "Classe=OPR, lexema=>, Tipo=None\n",
      "Classe=Num, lexema=2, Tipo=inteiro\n",
      "Classe=FC_P, lexema=), Tipo=None\n",
      "Classe=entao, lexema=entao, Tipo=entao\n",
      "Classe=se, lexema=se, Tipo=se\n",
      "Classe=AB_P, lexema=(, Tipo=None\n",
      "Classe=id, lexema=B, Tipo=None\n",
      "Classe=OPR, lexema=<=, Tipo=None\n",
      "Classe=Num, lexema=4, Tipo=inteiro\n",
      "Classe=FC_P, lexema=), Tipo=None\n",
      "Classe=entao, lexema=entao, Tipo=entao\n",
      "Classe=escreva, lexema=escreva, Tipo=escreva\n",
      "Classe=Lit, lexema=\"B esta entre 2 e 4\", Tipo=literal\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "Classe=fimse, lexema=fimse, Tipo=fimse\n",
      "Classe=fimse, lexema=fimse, Tipo=fimse\n",
      "Classe=id, lexema=B, Tipo=None\n",
      "Classe=ATR, lexema=<-, Tipo=None\n",
      "Classe=id, lexema=B, Tipo=None\n",
      "Classe=OPA, lexema=+, Tipo=None\n",
      "Classe=Num, lexema=1, Tipo=inteiro\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "Classe=id, lexema=B, Tipo=None\n",
      "Classe=ATR, lexema=<-, Tipo=None\n",
      "Classe=id, lexema=B, Tipo=None\n",
      "Classe=OPA, lexema=+, Tipo=None\n",
      "Classe=Num, lexema=2, Tipo=inteiro\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "Classe=id, lexema=B, Tipo=None\n",
      "Classe=ATR, lexema=<-, Tipo=None\n",
      "Classe=id, lexema=B, Tipo=None\n",
      "Classe=OPA, lexema=+, Tipo=None\n",
      "Classe=Num, lexema=3, Tipo=inteiro\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "Classe=id, lexema=D, Tipo=None\n",
      "Classe=ATR, lexema=<-, Tipo=None\n",
      "Classe=id, lexema=B, Tipo=None\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "Classe=id, lexema=C, Tipo=None\n",
      "Classe=ATR, lexema=<-, Tipo=None\n",
      "Classe=Num, lexema=5.0, Tipo=real\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "Classe=id, lexema=E, Tipo=None\n",
      "Classe=ATR, lexema=<-, Tipo=None\n",
      "Classe=id, lexema=B, Tipo=None\n",
      "Classe=OPA, lexema=+, Tipo=None\n",
      "Classe=Num, lexema=2, Tipo=inteiro\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "Classe=escreva, lexema=escreva, Tipo=escreva\n",
      "Classe=id, lexema=C, Tipo=None\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "Classe=id, lexema=B, Tipo=None\n",
      "Classe=ATR, lexema=<-, Tipo=None\n",
      "Classe=id, lexema=B, Tipo=None\n",
      "Classe=OPA, lexema=+, Tipo=None\n",
      "Classe=Num, lexema=1, Tipo=inteiro\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "Classe=escreva, lexema=escreva, Tipo=escreva\n",
      "Classe=Lit, lexema=\"\\nB=\\n\", Tipo=literal\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "ERRO LÉXICO - Caractere inválido na linguagem: Ã. Linha 1, coluna 282\n",
      "ERRO LÉXICO - Caractere inválido na linguagem: ©. Linha 1, coluna 283\n",
      "ERRO LÉXICO - Caractere inválido na linguagem: Ã. Linha 1, coluna 288\n",
      "ERRO LÉXICO - Caractere inválido na linguagem: ­. Linha 1, coluna 289\n",
      "Classe=Comentário, lexema={\\n Ã© o sÃ­mbolo para salto de linha}, Tipo=None\n",
      "Classe=escreva, lexema=escreva, Tipo=escreva\n",
      "Classe=id, lexema=D, Tipo=None\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "Classe=escreva, lexema=escreva, Tipo=escreva\n",
      "Classe=Lit, lexema=\"\\n\", Tipo=literal\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "Classe=escreva, lexema=escreva, Tipo=escreva\n",
      "Classe=id, lexema=C, Tipo=None\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "Classe=escreva, lexema=escreva, Tipo=escreva\n",
      "Classe=Lit, lexema=\"\\n\", Tipo=literal\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "Classe=escreva, lexema=escreva, Tipo=escreva\n",
      "Classe=id, lexema=A, Tipo=None\n",
      "Classe=PT_V, lexema=;, Tipo=None\n",
      "Classe=fim, lexema=fim, Tipo=fim\n",
      "Classe=EOF, lexema=EOF, Tipo=None\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afacd60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
